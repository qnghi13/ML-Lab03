{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcd86800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.1.0+cu118 (CUDA: 11.8)\n",
      "MMCV: 2.1.0\n",
      "Test load _ext: THÀNH CÔNG! (Đã nạp được C++ Extension)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import mmcv\n",
    "from mmpose.apis import MMPoseInferencer\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__} (CUDA: {torch.version.cuda})\")\n",
    "print(f\"MMCV: {mmcv.__version__}\")\n",
    "try:\n",
    "    from mmcv.ops import active_rotated_filter\n",
    "    print(\"Test load _ext: THÀNH CÔNG! (Đã nạp được C++ Extension)\")\n",
    "except Exception as e:\n",
    "    print(f\"Test load _ext: THẤT BẠI. Lỗi: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ef5521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- KẾT QUẢ KIỂM TRA MÔI TRƯỜNG ---\n",
      "Python: 3.9.25\n",
      "PyTorch: 2.7.1+cu118\n",
      "CUDA: 11.8\n",
      "Có GPU không?: True\n",
      "\n",
      ">>> HÃY CHẠY 2 LỆNH SAU TRONG TERMINAL (ANACONDA PROMPT):\n",
      "------------------------------------------------------------\n",
      "pip uninstall mmcv -y\n",
      "pip install mmcv==2.1.0 -f https://download.openmmlab.com/mmcv/dist/cu118/torch2.7.1/index.html\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "print(\"--- KẾT QUẢ KIỂM TRA MÔI TRƯỜNG ---\")\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.version.cuda}\")\n",
    "print(f\"Có GPU không?: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Logic tạo lệnh cài đặt\n",
    "try:\n",
    "    torch_ver = torch.__version__.split('+')[0] # ví dụ 2.1.0\n",
    "    cuda_ver = torch.version.cuda.replace('.', '') # ví dụ 118\n",
    "    \n",
    "    # URL kho chứa wheel của OpenMMLab\n",
    "    base_url = \"https://download.openmmlab.com/mmcv/dist\"\n",
    "    \n",
    "    # Tạo link tìm kiếm (find-links)\n",
    "    find_link = f\"{base_url}/cu{cuda_ver}/torch{torch_ver}/index.html\"\n",
    "    \n",
    "    print(\"\\n>>> HÃY CHẠY 2 LỆNH SAU TRONG TERMINAL (ANACONDA PROMPT):\")\n",
    "    print(\"-\" * 60)\n",
    "    print(\"pip uninstall mmcv -y\")\n",
    "    print(f'pip install mmcv==2.1.0 -f {find_link}')\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nLỗi khi tạo link: {e}\")\n",
    "    print(\"Có thể PyTorch của bạn là bản CPU hoặc phiên bản quá mới/cũ chưa được hỗ trợ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37fc458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tìm thấy file: archive (4).zip. Đang tiến hành giải nén...\n",
      "Giải nén thành công!\n",
      "\n",
      "HOÀN TẤT! Dữ liệu đã sẵn sàng tại: data/lsp\n",
      "Bạn có thể chạy tiếp phần code Đánh giá (Evaluation).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# 1. Cấu hình thư mục\n",
    "data_root = 'data/lsp'\n",
    "os.makedirs(data_root, exist_ok=True)\n",
    "\n",
    "# 2. Tìm file zip đã tải thủ công\n",
    "# Tìm bất kỳ file .zip nào ở thư mục hiện tại\n",
    "zip_files = glob.glob('*.zip') \n",
    "\n",
    "if not zip_files:\n",
    "    print(\"LỖI: Không tìm thấy file .zip nào!\")\n",
    "    print(\"Bạn vui lòng tải dataset từ Kaggle và upload file .zip vào thư mục này.\")\n",
    "else:\n",
    "    # Lấy file zip đầu tiên tìm thấy\n",
    "    zip_path = zip_files[0]\n",
    "    print(f\"Đã tìm thấy file: {zip_path}. Đang tiến hành giải nén...\")\n",
    "\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(data_root)\n",
    "        print(\"Giải nén thành công!\")\n",
    "        \n",
    "        # 3. Xử lý cấu trúc thư mục (Vì Kaggle thường lồng thư mục)\n",
    "        # Kiểm tra xem ảnh nằm ở đâu\n",
    "        images_path = os.path.join(data_root, 'images')\n",
    "        \n",
    "        # Trường hợp 1: Giải nén xong thấy thư mục 'lsp_dataset' bên trong (cấu trúc gốc)\n",
    "        sub_dir = os.path.join(data_root, 'lsp_dataset')\n",
    "        if os.path.exists(sub_dir):\n",
    "            # Di chuyển nội dung ra ngoài data_root\n",
    "            for item in os.listdir(sub_dir):\n",
    "                shutil.move(os.path.join(sub_dir, item), data_root)\n",
    "            os.rmdir(sub_dir)\n",
    "            print(\"Đã sắp xếp lại cấu trúc thư mục.\")\n",
    "\n",
    "        # Trường hợp 2: Kaggle đặt tên folder là 'leeds_sports_pose'\n",
    "        sub_dir_kaggle = os.path.join(data_root, 'leeds_sports_pose', 'leeds_sports_pose')\n",
    "        if os.path.exists(sub_dir_kaggle):\n",
    "             for item in os.listdir(sub_dir_kaggle):\n",
    "                shutil.move(os.path.join(sub_dir_kaggle, item), data_root)\n",
    "             print(\"Đã xử lý cấu trúc thư mục Kaggle.\")\n",
    "\n",
    "        # Kiểm tra cuối cùng\n",
    "        if os.path.exists(os.path.join(data_root, 'joints.mat')):\n",
    "             print(\"\\nHOÀN TẤT! Dữ liệu đã sẵn sàng tại: data/lsp\")\n",
    "             print(\"Bạn có thể chạy tiếp phần code Đánh giá (Evaluation).\")\n",
    "        else:\n",
    "             print(\"\\nCẢNH BÁO: Không tìm thấy file joints.mat. Hãy kiểm tra lại thư mục data/lsp\")\n",
    "\n",
    "    except zipfile.BadZipFile:\n",
    "        print(\"Lỗi: File zip bị hỏng. Vui lòng tải lại.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa7c2f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Khởi tạo model RTMPose...\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmpose-m_simcc-coco_pt-aic-coco_420e-256x192-d8dd5ca4_20230127.pth\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n",
      "Đang đọc Ground Truth...\n",
      "Bắt đầu chạy Inference trên 2000 ảnh...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:30<00:00, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "KẾT QUẢ ĐÁNH GIÁ TRÊN TẬP LSP (Subset 2000 ảnh)\n",
      "Model: rtmpose-m_8xb256-420e_coco-256x192\n",
      "Metric: PCK@0.3 (trên các khớp tay chân chính)\n",
      "Accuracy: 78.53%\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import cv2\n",
    "from mmpose.apis import MMPoseInferencer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. CẤU HÌNH\n",
    "DATA_DIR = 'data/lsp'\n",
    "IMG_DIR = os.path.join(DATA_DIR, 'images')\n",
    "GT_PATH = os.path.join(DATA_DIR, 'joints.mat')\n",
    "\n",
    "# Chọn model RTMPose-m (Medium) train trên COCO\n",
    "# MMPose sẽ tự động tải checkpoint về\n",
    "model_name = 'rtmpose-m_8xb256-420e_coco-256x192'\n",
    "\n",
    "# 2. HÀM MAPPING KEYPOINTS (COCO 17 điểm -> LSP 14 điểm)\n",
    "# Chúng ta chỉ so sánh 12 khớp chung (bỏ qua mắt, tai của COCO và Head-top/Neck của LSP để đơn giản hoá)\n",
    "# Thứ tự LSP: R Ankle(0), R Knee(1), R Hip(2), L Hip(3), L Knee(4), L Ankle(5), R Wrist(6), R Elbow(7), R Shoulder(8), L Shoulder(9), L Elbow(10), L Wrist(11), Neck(12), Head(13)\n",
    "# Thứ tự COCO: Nose(0), Eye(1-2), Ear(3-4), Shoulder(5-6), Elbow(7-8), Wrist(9-10), Hip(11-12), Knee(13-14), Ankle(15-16)\n",
    "\n",
    "# Map: LSP index -> COCO index\n",
    "joint_map = {\n",
    "    0: 16, # R Ankle\n",
    "    1: 14, # R Knee\n",
    "    2: 12, # R Hip\n",
    "    3: 11, # L Hip\n",
    "    4: 13, # L Knee\n",
    "    5: 15, # L Ankle\n",
    "    6: 10, # R Wrist\n",
    "    7: 8,  # R Elbow\n",
    "    8: 6,  # R Shoulder\n",
    "    9: 5,  # L Shoulder\n",
    "    10: 7, # L Elbow\n",
    "    11: 9  # L Wrist\n",
    "}\n",
    "eval_indices = list(joint_map.keys()) # Chỉ đánh giá các khớp có trong map\n",
    "\n",
    "# 3. HÀM TÍNH PCK (Percentage of Correct Keypoints)\n",
    "def calculate_pck(predictions, ground_truths, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Tính PCK dựa trên đường chéo bounding box của thân người (Torso Diameter)\n",
    "    \"\"\"\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for pred, gt in zip(predictions, ground_truths):\n",
    "        # Lấy các khớp vai và hông để tính kích thước thân người\n",
    "        # LSP: R Hip(2), L Hip(3), R Shoulder(8), L Shoulder(9)\n",
    "        if gt.shape[1] > 2 and gt[2, 2] == 0: continue # Skip nếu không hiện hữu (visible)\n",
    "\n",
    "        # Tính kích thước tham chiếu (Torso diameter)\n",
    "        r_shoulder = gt[8, :2]\n",
    "        l_hip = gt[3, :2]\n",
    "        torso_size = np.linalg.norm(r_shoulder - l_hip)\n",
    "        if torso_size == 0: torso_size = 100 # Fallback\n",
    "\n",
    "        thr = threshold * torso_size\n",
    "\n",
    "        for lsp_idx in eval_indices:\n",
    "            # Kiểm tra xem khớp có visible trong GT không (cột thứ 3 của LSP là invisible flag?)\n",
    "            # Lưu ý: LSP joints shape là (3, 14, 2000). Cột 3: 0: hidden, 1: visible\n",
    "            # Ở đây ta lấy 100 ảnh đầu để demo nhanh\n",
    "            pass\n",
    "\n",
    "            coco_idx = joint_map[lsp_idx]\n",
    "            \n",
    "            # Lấy toạ độ\n",
    "            pred_pt = pred[coco_idx][:2] # x, y\n",
    "            gt_pt = gt[lsp_idx][:2]      # x, y\n",
    "\n",
    "            # Tính khoảng cách\n",
    "            dist = np.linalg.norm(pred_pt - gt_pt)\n",
    "            \n",
    "            if dist <= thr:\n",
    "                correct_count += 1\n",
    "            total_count += 1\n",
    "            \n",
    "    return correct_count / total_count if total_count > 0 else 0\n",
    "\n",
    "# 4. CHẠY THỰC NGHIỆM\n",
    "print(\"Khởi tạo model RTMPose...\")\n",
    "inferencer = MMPoseInferencer(model_name)\n",
    "\n",
    "print(\"Đang đọc Ground Truth...\")\n",
    "# Load file mat: shape gốc là (3, 14, 2000) -> transpose thành (2000, 14, 3) cho dễ dùng\n",
    "joints_gt = sio.loadmat(GT_PATH)['joints'].transpose(2, 1, 0) \n",
    "\n",
    "# Chỉ test trên 100 ảnh đầu tiên để tiết kiệm thời gian (có thể tăng lên 2000 nếu muốn full)\n",
    "NUM_TEST = 2000 \n",
    "preds_list = []\n",
    "gt_list = []\n",
    "\n",
    "print(f\"Bắt đầu chạy Inference trên {NUM_TEST} ảnh...\")\n",
    "for i in tqdm(range(NUM_TEST)):\n",
    "    img_name = f\"im{i+1:04d}.jpg\" # Tên file ảnh LSP: im0001.jpg, im0002.jpg...\n",
    "    img_path = os.path.join(IMG_DIR, img_name)\n",
    "    \n",
    "    if not os.path.exists(img_path): continue\n",
    "\n",
    "    # Chạy Inference\n",
    "    result_generator = inferencer(img_path, return_vis=False)\n",
    "    result = next(result_generator)\n",
    "    \n",
    "    # Lấy danh sách người detect được trong ảnh đầu tiên\n",
    "    detected_people = result['predictions'][0] # Đây là một LIST\n",
    "    \n",
    "    # Kiểm tra xem có detect được ai không\n",
    "    if not detected_people:\n",
    "        print(f\"Bỏ qua {img_name}: Không tìm thấy người.\")\n",
    "        continue\n",
    "        \n",
    "    # Lấy người đầu tiên (thường là người chính giữa hoặc rõ nhất trong LSP)\n",
    "    first_person = detected_people[0] # Đây mới là DICT\n",
    "    \n",
    "    # Lấy keypoints của người đó\n",
    "    keypoints = np.array(first_person['keypoints'])\n",
    "    preds_list.append(keypoints)\n",
    "    \n",
    "    # Lấy Ground Truth tương ứng (nhớ đổi shape nếu cần thiết ở bước load mat file)\n",
    "    gt_list.append(joints_gt[i])\n",
    "\n",
    "# 5. KẾT QUẢ\n",
    "pck_score = calculate_pck(preds_list, gt_list, threshold=0.2)\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(f\"KẾT QUẢ ĐÁNH GIÁ TRÊN TẬP LSP (Subset {NUM_TEST} ảnh)\")\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Metric: PCK@0.3 (trên các khớp tay chân chính)\")\n",
    "print(f\"Accuracy: {pck_score * 100:.2f}%\")\n",
    "print(\"=\"*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
