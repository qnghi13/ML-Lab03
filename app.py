# import streamlit as st
# import cv2
# import numpy as np
# import tempfile
# import math
# from mmpose.apis import MMPoseInferencer

# # --- C·∫§U H√åNH ---
# MODEL_CFG = 'rtmpose-m_8xb256-420e_coco-256x192' 
# CONFIDENCE_THRESHOLD = 0.5 
# DOWN_ANGLE_THRESH = 90
# UP_ANGLE_THRESH = 160
# FRAME_SKIP = 5 

# # --- H√ÄM T√çNH G√ìC KHU·ª∂U TAY ---
# def calculate_angle(a, b, c):
#     a, b, c = np.array(a), np.array(b), np.array(c)
#     radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])
#     angle = np.abs(radians * 180.0 / np.pi)
#     if angle > 180.0: angle = 360 - angle
#     return angle

# def check_body_posture(kpts, scores):
#     """
#     Ki·ªÉm tra t∆∞ th·∫ø Push-up h·ªó tr·ª£ c·∫£ g√≥c nghi√™ng (Side) v√† tr·ª±c di·ªán (Front).
#     Input: kpts (m·∫£ng 17x2), scores (m·∫£ng 17)
#     """
#     # Index COCO: L_Shoulder(5), R_Shoulder(6), L_Hip(11), R_Hip(12), L_Ankle(15), R_Ankle(16)
    
#     # 1. L·∫•y t·ªça ƒë·ªô trung b√¨nh Vai v√† H√¥ng
#     shoulder_y = (kpts[5][1] + kpts[6][1]) / 2
#     shoulder_x_dist = abs(kpts[5][0] - kpts[6][0]) # Chi·ªÅu r·ªông vai
    
#     hip_y = (kpts[11][1] + kpts[12][1]) / 2
    
#     # L·∫•y ƒëi·ªÉm ch√¢n (∆∞u ti√™n Ankle, n·∫øu kh√¥ng th·∫•y th√¨ l·∫•y Hip l√†m chu·∫©n t·∫°m)
#     if scores[15] > 0.3 or scores[16] > 0.3:
#         ankle_y = (kpts[15][1] + kpts[16][1]) / 2
#         ankle_x = (kpts[15][0] + kpts[16][0]) / 2
#     else:
#         # N·∫øu ch√¢n b·ªã khu·∫•t (th∆∞·ªùng g·∫∑p ·ªü front view), d√πng H√¥ng ƒë·ªÉ t√≠nh g√≥c
#         ankle_y, ankle_x = hip_y, (kpts[11][0] + kpts[12][0]) / 2

#     shoulder_center_x = (kpts[5][0] + kpts[6][0]) / 2
    
#     # 2. T√≠nh g√≥c nghi√™ng c∆° th·ªÉ (Side View Logic)
#     dy = ankle_y - shoulder_y
#     dx = ankle_x - shoulder_center_x
#     angle_rad = math.atan2(abs(dy), abs(dx))
#     angle_deg = math.degrees(angle_rad)
    
#     # CASE A: N·∫±m ngang (Side View) -> G√≥c < 60 ƒë·ªô
#     if angle_deg < 60:
#         return True, angle_deg, "Side View"

#     # CASE B: H∆∞·ªõng ƒë·∫ßu v√†o Cam (Front View) -> G√≥c ~ 90 ƒë·ªô (ƒê·ª©ng)
#     # L√∫c n√†y ta check t·ª∑ l·ªá Th√¢n / Vai
#     # ·ªû g√≥c tr·ª±c di·ªán, th√¢n (Vai xu·ªëng H√¥ng) b·ªã ng·∫Øn l·∫°i do ph·ªëi c·∫£nh
#     torso_length = abs(hip_y - shoulder_y)
    
#     # Ng∆∞·ª°ng: N·∫øu chi·ªÅu d√†i th√¢n < 1.4 l·∫ßn chi·ªÅu r·ªông vai -> ƒêang n·∫±m h∆∞·ªõng v√†o cam
#     # (Ng∆∞·ªùi ƒë·ª©ng b√¨nh th∆∞·ªùng th√¨ th√¢n d√†i h∆°n vai nhi·ªÅu)
#     if shoulder_x_dist > 0: # Tr√°nh chia cho 0
#         ratio = torso_length / shoulder_x_dist
#         if ratio < 1.4: 
#             return True, angle_deg, f"Front View (R={ratio:.1f})"
    
#     return False, angle_deg, "Stand Up"

# # --- GIAO DI·ªÜN ---
# st.set_page_config(page_title="Smart AI Push-up Counter", layout="wide")
# st.title("üõ°Ô∏è Smart AI Push-up (Anti-Cheat)")
# st.markdown("Phi√™n b·∫£n t√≠ch h·ª£p **Posture Check**: Ch·ªâ ƒë·∫øm khi ng∆∞·ªùi d√πng n·∫±m ·ªü t∆∞ th·∫ø Push-up.")

# st.sidebar.header("C√†i ƒë·∫∑t")
# source_option = st.sidebar.selectbox("Ch·ªçn ngu·ªìn video", ["Webcam", "Upload Video"])

# @st.cache_resource
# def load_model():
#     return MMPoseInferencer(pose2d=MODEL_CFG)

# with st.spinner('ƒêang t·∫£i m√¥ h√¨nh AI...'):
#     inferencer = load_model()

# # --- H√ÄM T√åM KI·∫æM WEBCAM ---
# def get_webcams():
#     """Ki·ªÉm tra 5 c·ªïng ƒë·∫ßu ti√™n (0-4) ƒë·ªÉ t√¨m camera."""
#     available_cams = []
#     # Ki·ªÉm tra 5 index ƒë·∫ßu ti√™n (th∆∞·ªùng camera ch·ªâ n·∫±m trong kho·∫£ng 0-3)
#     for i in range(5): 
#         # Th·ª≠ m·ªü camera v·ªõi backend DirectShow (t·ªët cho Windows/Camera ·∫£o)
#         cap = cv2.VideoCapture(i, cv2.CAP_DSHOW) 
        
#         # N·∫øu kh√¥ng d√πng Windows, ho·∫∑c code tr√™n l·ªói, h√£y th·ª≠ d√≤ng d∆∞·ªõi (b·ªè comment):
#         # cap = cv2.VideoCapture(i) 
        
#         if cap.isOpened():
#             ret, _ = cap.read()
#             if ret:
#                 available_cams.append(i)
#             cap.release()
#     return available_cams

# input_path = None
# if source_option == "Upload Video":
#     uploaded_file = st.sidebar.file_uploader("T·∫£i l√™n video...", type=['mp4', 'mov', 'avi'])
#     if uploaded_file is not None:
#         tfile = tempfile.NamedTemporaryFile(delete=False)
#         tfile.write(uploaded_file.read())
#         input_path = tfile.name
# elif source_option == "Webcam":
#     webcam_indices = get_webcams()
#     if webcam_indices:
#         # T·∫°o danh s√°ch hi·ªÉn th·ªã
#         webcam_options = {f"Webcam {i}": i for i in webcam_indices}
        
#         selected_key = st.sidebar.selectbox(
#             "Ch·ªçn Webcam:", 
#             list(webcam_options.keys())
#         )
#         input_path = webcam_options[selected_key]
#         st.sidebar.info(f"ƒêang s·ª≠ d·ª•ng Webcam {input_path}")
#     else:
#         st.sidebar.error("Kh√¥ng t√¨m th·∫•y webcam n√†o. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi.")

# start_button = st.sidebar.button("B·∫Øt ƒë·∫ßu Ph√¢n t√≠ch", type="primary")
# stop_button = st.sidebar.button("D·ª´ng l·∫°i")

# if start_button and input_path is not None:
#     cap = cv2.VideoCapture(input_path, cv2.CAP_DSHOW)
    
#     width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#     height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
#     # Adaptive Layout
#     if width < height: 
#         col1, col2, col3 = st.columns([2, 2, 2])
#         with col2: st_frame = st.empty()
#     else:
#         col1, col2, col3 = st.columns([0.5, 4, 0.5])
#         with col2: st_frame = st.empty()

#     st_info = st.sidebar.empty()
    
#     counter = 0
#     stage = "UP"
#     active_arm = "None"
#     frame_count = 0
#     posture_status = "Waiting..." # Tr·∫°ng th√°i t∆∞ th·∫ø
#     posture_valid = False
    
#     last_viz_frame = None 

#     while cap.isOpened():
#         if stop_button: break
        
#         ret, frame = cap.read()
#         if not ret:
#             st.sidebar.warning("K·∫øt th√∫c video.")
#             break
            
#         if frame.shape[1] > 1280:
#             scale = 1280 / frame.shape[1]
#             frame = cv2.resize(frame, None, fx=scale, fy=scale)

#         frame_count += 1
        
#         if frame_count % FRAME_SKIP == 0:
#             result_generator = inferencer(frame, return_vis=False)
#             result = next(result_generator)
#             viz_frame = frame.copy()
            
#             predictions = result['predictions'][0]
#             if predictions:
#                 person = predictions[0]
#                 kpts = np.array(person['keypoints'])
#                 scores = np.array(person['keypoint_scores'])

#                 l_pts = [kpts[5], kpts[7], kpts[9]] # Vai, Khu·ª∑u, C·ªï tay tr√°i
#                 r_pts = [kpts[6], kpts[8], kpts[10]] # Vai, Khu·ª∑u, C·ªï tay ph·∫£i
                
#                 # ƒêi·ªÉm d√πng ƒë·ªÉ check t∆∞ th·∫ø: Vai v√† C·ªï ch√¢n (Ankle)
#                 # COCO Ankle: Left(15), Right(16)
#                 # N·∫øu kh√¥ng th·∫•y ch√¢n, d√πng H√¥ng: Left(11), Right(12)
#                 l_body_pts = [kpts[5], kpts[15] if scores[15] > 0.3 else kpts[11]] 
#                 r_body_pts = [kpts[6], kpts[16] if scores[16] > 0.3 else kpts[12]]

#                 l_conf = (scores[5] + scores[7] + scores[9]) / 3
#                 r_conf = (scores[6] + scores[8] + scores[10]) / 3

#                 current_angle = 0
#                 selected_color = (0, 0, 0)
                
#                 # --- CH·ªåN TAY ---
#                 if l_conf > CONFIDENCE_THRESHOLD and l_conf >= r_conf:
#                     active_arm = "Left"
#                     current_angle = calculate_angle(l_pts[0], l_pts[1], l_pts[2])
#                     target_pts, target_elbow = l_pts, l_pts[1]
#                     body_segment = l_body_pts
#                     selected_color = (0, 255, 0)
#                 elif r_conf > CONFIDENCE_THRESHOLD and r_conf > l_conf:
#                     active_arm = "Right"
#                     current_angle = calculate_angle(r_pts[0], r_pts[1], r_pts[2])
#                     target_pts, target_elbow = r_pts, r_pts[1]
#                     body_segment = r_body_pts
#                     selected_color = (255, 165, 0)
#                 else:
#                     active_arm = "Lost"
                
#                 if active_arm != "Lost":
#                     # Truy·ªÅn to√†n b·ªô kpts v√† scores v√†o h√†m m·ªõi
#                     is_valid_pose, body_angle, view_mode = check_body_posture(kpts, scores)
                    
#                     if is_valid_pose:
#                         posture_valid = True
#                         posture_status = f"Push-up ({view_mode})" # Hi·ªán r√µ ƒëang view g√≥c n√†o
                        
#                         # Logic ƒë·∫øm (gi·ªØ nguy√™n)
#                         if current_angle > UP_ANGLE_THRESH: stage = "UP"
#                         if current_angle < DOWN_ANGLE_THRESH and stage == "UP":
#                             stage = "DOWN"
#                             counter += 1
                        
#                         # V·∫Ω m√†u Xanh/Cam
#                         cv2.line(viz_frame, (int(target_pts[0][0]), int(target_pts[0][1])), (int(target_pts[1][0]), int(target_pts[1][1])), selected_color, 4)
#                         cv2.line(viz_frame, (int(target_pts[1][0]), int(target_pts[1][1])), (int(target_pts[2][0]), int(target_pts[2][1])), selected_color, 4)
#                         cv2.putText(viz_frame, str(int(current_angle)), (int(target_elbow[0]), int(target_elbow[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

#                     else:
#                         posture_status = "Stand Up"
#                         # V·∫Ω m√†u ƒê·ªè
#                         cv2.line(viz_frame, (int(target_pts[0][0]), int(target_pts[0][1])), (int(target_pts[1][0]), int(target_pts[1][1])), (0, 0, 255), 4)
#                         cv2.line(viz_frame, (int(target_pts[1][0]), int(target_pts[1][1])), (int(target_pts[2][0]), int(target_pts[2][1])), (0, 0, 255), 4)
#             last_viz_frame = viz_frame
            
#             # C·∫≠p nh·∫≠t th√¥ng s·ªë
#             st_info.markdown(f"""
#             ### üìä Th·ªëng k√™
#             - **S·ªë l·∫ßn:** {counter}
#             - **Tay:** {active_arm}
#             - **T∆∞ th·∫ø:** {posture_status}
#             - **G√≥c g·∫≠p khu·ª∑u tay:** {int(current_angle) if active_arm != 'Lost' else 0}¬∞
#             - **G√≥c nghi√™ng th√¢n:** {int(body_angle) if active_arm != 'Lost' else 0}¬∞
#             """)
        
#         else:
#             if last_viz_frame is not None: viz_frame = last_viz_frame
#             else: viz_frame = frame

#         # V·∫Ω Info Box
#         # ƒê·ªïi m√†u box n·∫øu sai t∆∞ th·∫ø
#         box_color = (0, 200, 0) if posture_valid else (50, 50, 200)
        
#         cv2.rectangle(viz_frame, (0,0), (310, 85), box_color, -1)
#         cv2.putText(viz_frame, f'REPS: {counter}', (10,35), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)
#         cv2.putText(viz_frame, f'{posture_status}', (10,70), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1)

#         st_frame.image(viz_frame, channels="BGR", width='stretch')
        
#     cap.release()



import streamlit as st
import cv2
import numpy as np
import tempfile
import math
from mmpose.apis import MMPoseInferencer

# --- C·∫§U H√åNH H·ªÜ TH·ªêNG ---
st.set_page_config(
    page_title="AI Push-up Trainer",
    page_icon="üí™",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Config Model
MODEL_CFG = 'rtmpose-m_8xb256-420e_coco-256x192' 
CONFIDENCE_THRESHOLD = 0.5 
DOWN_ANGLE_THRESH = 90
UP_ANGLE_THRESH = 160
FRAME_SKIP = 5 
MAX_DIMENSION = 1280 # Gi·ªõi h·∫°n c·∫°nh l·ªõn nh·∫•t (ƒë·ªÉ t·ªëi ∆∞u FPS v√† hi·ªÉn th·ªã)

# --- CSS: T·ªêI ∆ØU GIAO DI·ªÜN ---
st.markdown("""
<style>
    [data-testid="stSidebar"] { background-color: #1e1e24; color: white; }
    .stMetric { background-color: #f0f2f6; border-radius: 10px; padding: 10px; border: 1px solid #e0e0e0; }
    /* CƒÉn gi·ªØa video */
    div.stImage { display: flex; justify-content: center; }
    div.stImage > img { object-fit: contain; max-height: 80vh; } 
</style>
""", unsafe_allow_html=True)

# --- C√ÅC H√ÄM X·ª¨ L√ù LOGIC (CORE LOGIC) ---
def calculate_angle(a, b, c):
    a, b, c = np.array(a), np.array(b), np.array(c)
    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])
    angle = np.abs(radians * 180.0 / np.pi)
    if angle > 180.0: angle = 360 - angle
    return angle

def check_body_posture(kpts, scores):
    """
    LOGIC V2: Y√™u c·∫ßu th·∫•y to√†n th√¢n (ho·∫∑c √≠t nh·∫•t l√† ƒë·∫ßu g·ªëi) m·ªõi b·∫Øt ƒë·∫ßu x√©t duy·ªát.
    """
    # 1. ƒê·ªãnh nghƒ©a c√°c ƒëi·ªÉm quan tr·ªçng
    # COCO Keypoints: 
    # Vai: 5,6 | H√¥ng: 11,12 | ƒê·∫ßu g·ªëi: 13,14 | C·ªï ch√¢n: 15,16
    
    avg_shoulder_conf = (scores[5] + scores[6]) / 2
    avg_hip_conf = (scores[11] + scores[12]) / 2
    
    # Ki·ªÉm tra xem c√≥ th·∫•y Ch√¢n (Knee ho·∫∑c Ankle) kh√¥ng?
    # Ch·ªâ c·∫ßn th·∫•y 1 trong 2 b√™n (Tr√°i ho·∫∑c Ph·∫£i) l√† ƒë·ªß
    has_knees = scores[13] > 0.4 or scores[14] > 0.4
    has_ankles = scores[15] > 0.4 or scores[16] > 0.4
    
    # --- ƒêI·ªÄU KI·ªÜN 1: PH·∫¢I TH·∫§Y NG∆Ø·ªúI ---
    # N·∫øu kh√¥ng th·∫•y vai, h√¥ng HO·∫∂C (kh√¥ng th·∫•y ƒë·∫ßu g·ªëi V√Ä kh√¥ng th·∫•y c·ªï ch√¢n)
    if avg_shoulder_conf < 0.4 or avg_hip_conf < 0.4 or (not has_knees and not has_ankles):
        return False, 0, "Show Full Body" # B·∫Øt bu·ªôc ph·∫£i l√πi ra xa ƒë·ªÉ th·∫•y ch√¢n

    # 2. L·∫•y t·ªça ƒë·ªô
    shoulder_y = (kpts[5][1] + kpts[6][1]) / 2
    shoulder_center_x = (kpts[5][0] + kpts[6][0]) / 2
    shoulder_width = abs(kpts[5][0] - kpts[6][0])
    
    hip_y = (kpts[11][1] + kpts[12][1]) / 2
    
    # ∆Øu ti√™n l·∫•y Ankle l√†m m·ªëc, n·∫øu kh√¥ng th√¨ l·∫•y Knee (cho ki·ªÉu h√≠t ƒë·∫•t qu·ª≥ g·ªëi)
    if has_ankles:
        foot_y = (kpts[15][1] + kpts[16][1]) / 2
        foot_x = (kpts[15][0] + kpts[16][0]) / 2
        body_part = "Ankles"
    else:
        foot_y = (kpts[13][1] + kpts[14][1]) / 2
        foot_x = (kpts[13][0] + kpts[14][0]) / 2
        body_part = "Knees"

    # 3. T√≠nh g√≥c nghi√™ng th√¢n ng∆∞·ªùi (Vai n·ªëi t·ªõi Ch√¢n)
    dy = foot_y - shoulder_y
    dx = foot_x - shoulder_center_x
    angle_rad = math.atan2(abs(dy), abs(dx))
    angle_deg = math.degrees(angle_rad)
    
    # --- ƒêI·ªÄU KI·ªÜN 2: PH√ÇN LO·∫†I VIEW ---
    
    # CASE A: Side View (N·∫±m ngang) -> G√≥c < 50 ƒë·ªô (Si·∫øt ch·∫∑t h∆°n 60)
    if angle_deg < 50:
        return True, angle_deg, f"Side View ({body_part})"

    # CASE B: Front View (Tr·ª±c di·ªán)
    # Logic: Khi n·∫±m tr·ª±c di·ªán, th√¢n ng∆∞·ªùi (Vai->H√¥ng) s·∫Ω b·ªã ng·∫Øn l·∫°i so v·ªõi Vai.
    torso_length = abs(hip_y - shoulder_y)
    
    if shoulder_width > 0:
        ratio = torso_length / shoulder_width
        # N·∫øu ng·ªìi: Th√¢n r·∫•t d√†i so v·ªõi vai (Ratio > 1.5 - 2.0)
        # N·∫øu h√≠t ƒë·∫•t tr·ª±c di·ªán: Th√¢n ng·∫Øn l·∫°i (Ratio < 1.3)
        if ratio < 1.3: 
            return True, angle_deg, f"Front View (R={ratio:.1f})"
        else:
            return False, angle_deg, "Sitting/Standing" # Ph√°t hi·ªán ng·ªìi
            
    return False, angle_deg, "Wrong Pose"

# --- H√ÄM X·ª¨ L√ù H√åNH ·∫¢NH & GIAO DI·ªÜN (NEW) ---

def smart_resize(frame, max_dim=1280):
    """
    Resize th√¥ng minh: Gi·ªØ nguy√™n t·ª∑ l·ªá khung h√¨nh.
    Ch·ªâ resize n·∫øu ·∫£nh qu√° l·ªõn ƒë·ªÉ ƒë·∫£m b·∫£o t·ªëc ƒë·ªô x·ª≠ l√Ω.
    """
    h, w = frame.shape[:2]
    if max(h, w) > max_dim:
        scale = max_dim / max(h, w)
        new_w = int(w * scale)
        new_h = int(h * scale)
        return cv2.resize(frame, (new_w, new_h))
    return frame

def draw_hud_responsive(img, counter, stage, posture_status, angle, is_valid):
    """
    V·∫Ω HUD t·ª± ƒë·ªông co gi√£n theo ƒë·ªô ph√¢n gi·∫£i c·ªßa video.
    """
    h, w = img.shape[:2]
    
    # T√≠nh to√°n Scale Factor (D·ª±a tr√™n chi·ªÅu r·ªông chu·∫©n 1280px)
    # N·∫øu ·∫£nh r·ªông 640px -> scale = 0.5. N·∫øu 1920px -> scale = 1.5
    s = w / 1280.0 
    s = max(s, 0.5) # Kh√¥ng cho nh·ªè qu√° m·ª©c ƒë·ªçc ƒë∆∞·ª£c

    overlay = img.copy()
    
    # M√†u s·∫Øc
    status_color = (0, 255, 0) if is_valid else (0, 0, 255)
    
    # 1. Header Bar (Chi·ªÅu cao thay ƒë·ªïi theo scale)
    bar_height = int(80 * s)
    cv2.rectangle(overlay, (0, 0), (w, bar_height), (0, 0, 0), -1)
    
    # Tr·ªôn m√†u (Transparency)
    alpha = 0.7
    cv2.addWeighted(overlay, alpha, img, 1 - alpha, 0, img)
    
    # 2. Th√¥ng s·ªë (Font size v√† v·ªã tr√≠ nh√¢n v·ªõi s)
    # REPS
    cv2.putText(img, "REPS", (int(20*s), int(30*s)), cv2.FONT_HERSHEY_SIMPLEX, 0.6*s, (200, 200, 200), 1)
    cv2.putText(img, str(counter), (int(20*s), int(70*s)), cv2.FONT_HERSHEY_DUPLEX, 1.2*s, (255, 255, 255), int(2*s))
    
    # STAGE
    stage_color = (0, 255, 255) if stage == "DOWN" else (255, 255, 255)
    cv2.putText(img, "STAGE", (int(150*s), int(30*s)), cv2.FONT_HERSHEY_SIMPLEX, 0.6*s, (200, 200, 200), 1)
    cv2.putText(img, stage, (int(150*s), int(70*s)), cv2.FONT_HERSHEY_DUPLEX, 1.0*s, stage_color, int(2*s))
    
    # ANGLE
    cv2.putText(img, "ANGLE", (int(300*s), int(30*s)), cv2.FONT_HERSHEY_SIMPLEX, 0.6*s, (200, 200, 200), 1)
    cv2.putText(img, f"{int(angle)}", (int(300*s), int(70*s)), cv2.FONT_HERSHEY_DUPLEX, 1.0*s, (255, 255, 255), int(2*s))

    # WARNING BAR (Bottom)
    if not is_valid:
        warn_height = int(40 * s)
        cv2.rectangle(img, (0, h - warn_height), (w, h), (0, 0, 255), -1)
        cv2.putText(img, f"WARN: {posture_status}", (int(20*s), h - int(10*s)), cv2.FONT_HERSHEY_SIMPLEX, 0.7*s, (255, 255, 255), int(2*s))
    else:
        cv2.putText(img, f"Mode: {posture_status}", (w - int(250*s), int(30*s)), cv2.FONT_HERSHEY_SIMPLEX, 0.5*s, (0, 255, 0), 1)

    return img

def get_webcams():
    """Scan webcam t·ª± ƒë·ªông"""
    available_cams = []
    for i in range(4): 
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            available_cams.append(i)
            cap.release()
    return available_cams

# --- KH·ªûI T·∫†O H·ªÜ TH·ªêNG ---
st.sidebar.title("üõ†Ô∏è Control Panel")
source_option = st.sidebar.radio("Ngu·ªìn Video:", ["Webcam", "Upload Video"])

input_path = None
if source_option == "Upload Video":
    uploaded_file = st.sidebar.file_uploader("Ch·ªçn file video...", type=['mp4', 'mov', 'avi'])
    if uploaded_file is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_file.read())
        input_path = tfile.name
elif source_option == "Webcam":
    webcam_indices = get_webcams()
    if webcam_indices:
        webcam_dict = {f"Camera {i}": i for i in webcam_indices}
        selected_cam = st.sidebar.selectbox("Ch·ªçn thi·∫øt b·ªã:", list(webcam_dict.keys()))
        input_path = webcam_dict[selected_cam]
    else:
        st.sidebar.error("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y Webcam!")

# Load Model
@st.cache_resource
def load_model():
    return MMPoseInferencer(pose2d=MODEL_CFG)

if 'is_active' not in st.session_state:
    st.session_state['is_active'] = False

# 2. N√∫t b·∫•m ch·ªâ l√†m nhi·ªám v·ª• "B·∫≠t c√¥ng t·∫Øc" (ƒê·ªïi tr·∫°ng th√°i)
if st.sidebar.button("üöÄ K√çCH HO·∫†T H·ªÜ TH·ªêNG", type="primary"):
    st.session_state['is_active'] = True

# 3. Load Model d·ª±a tr√™n tr·∫°ng th√°i (Ch·∫°y m·ªói khi reload trang)
inferencer = None
if st.session_state['is_active']:
    with st.spinner('ƒêang x·ª≠ l√Ω AI...'):
        inferencer = load_model()

if st.sidebar.button("‚èπÔ∏è D·ª´ng l·∫°i"): st.session_state['is_active'] = False

# --- LAYOUT CH√çNH ---
st.title("üí™ AI Push-up Trainer")
st.markdown("H·ªá th·ªëng ch·∫•m ƒëi·ªÉm Push-up chu·∫©n thi ƒë·∫•u (Strict Form).")

# Layout Responsive: C·ªôt video t·ª± co gi√£n, C·ªôt ch·ªâ s·ªë c·ªë ƒë·ªãnh
main_col1, main_col2 = st.columns([3, 1]) 

with main_col2:
    st.subheader("üìä Ch·ªâ s·ªë")
    metric_count = st.empty()
    metric_stage = st.empty()
    metric_pose = st.empty()
    
    metric_count.metric("S·ªë l·∫ßn (Reps)", "0")
    metric_stage.metric("Tr·∫°ng th√°i", "READY")
    metric_pose.info("ƒêang ch·ªù video...")

with main_col1:
    st_frame = st.empty()

# --- MAIN LOOP ---
if st.session_state['is_active'] and input_path is not None:
    # Auto backend select (Fix m√†n h√¨nh ƒëen)
    cap = cv2.VideoCapture(input_path)
    
    counter = 0
    stage = "UP"
    active_arm = "None"
    frame_count = 0
    posture_status = "Waiting..."
    posture_valid = False
    last_viz_frame = None 

    while cap.isOpened() and st.session_state['is_active']:
        ret, frame = cap.read()
        if not ret:
            st.warning("K·∫øt th√∫c video.")
            st.session_state['is_active'] = False
            break
            
        # --- B∆Ø·ªöC 1: SMART RESIZE ---
        # ƒê∆∞a v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n x·ª≠ l√Ω (kh√¥ng qu√° 1280px chi·ªÅu d√†i)
        # Gi√∫p FPS ·ªïn ƒë·ªãnh v√† HUD hi·ªÉn th·ªã ƒë·ªìng nh·∫•t
        frame = smart_resize(frame, MAX_DIMENSION)

        frame_count += 1
        
        if frame_count % FRAME_SKIP == 0:
            result_generator = inferencer(frame, return_vis=False)
            result = next(result_generator)
            viz_frame = frame.copy()
            
            predictions = result['predictions'][0]
            if predictions:
                person = predictions[0]
                kpts = np.array(person['keypoints'])
                scores = np.array(person['keypoint_scores'])

                l_pts = [kpts[5], kpts[7], kpts[9]]
                r_pts = [kpts[6], kpts[8], kpts[10]]
                
                l_conf = (scores[5] + scores[7] + scores[9]) / 3
                r_conf = (scores[6] + scores[8] + scores[10]) / 3

                current_angle = 0
                s = frame.shape[1] / 1280.0 # Scale factor cho ƒë·ªô d√†y n√©t v·∫Ω
                thick = max(int(4 * s), 1)

                if l_conf > CONFIDENCE_THRESHOLD and l_conf >= r_conf:
                    active_arm = "Left"
                    current_angle = calculate_angle(l_pts[0], l_pts[1], l_pts[2])
                    target_pts = l_pts
                elif r_conf > CONFIDENCE_THRESHOLD and r_conf > l_conf:
                    active_arm = "Right"
                    current_angle = calculate_angle(r_pts[0], r_pts[1], r_pts[2])
                    target_pts = r_pts
                else:
                    active_arm = "Lost"
                
                if active_arm != "Lost":
                    is_valid_pose, body_angle, view_mode = check_body_posture(kpts, scores)
                    posture_valid = is_valid_pose
                    posture_status = view_mode 

                    if is_valid_pose:
                        if current_angle > UP_ANGLE_THRESH: stage = "UP"
                        if current_angle < DOWN_ANGLE_THRESH and stage == "UP":
                            stage = "DOWN"
                            counter += 1
                        
                        # V·∫Ω X∆∞∆°ng Xanh
                        cv2.line(viz_frame, (int(target_pts[0][0]), int(target_pts[0][1])), (int(target_pts[1][0]), int(target_pts[1][1])), (0, 255, 0), thick)
                        cv2.line(viz_frame, (int(target_pts[1][0]), int(target_pts[1][1])), (int(target_pts[2][0]), int(target_pts[2][1])), (0, 255, 0), thick)
                    else:
                        # V·∫Ω X∆∞∆°ng ƒê·ªè
                        cv2.line(viz_frame, (int(target_pts[0][0]), int(target_pts[0][1])), (int(target_pts[1][0]), int(target_pts[1][1])), (0, 0, 255), thick)
                        cv2.line(viz_frame, (int(target_pts[1][0]), int(target_pts[1][1])), (int(target_pts[2][0]), int(target_pts[2][1])), (0, 0, 255), thick)
            
            # --- B∆Ø·ªöC 2: V·∫º HUD RESPONSIVE ---
            viz_frame = draw_hud_responsive(viz_frame, counter, stage, posture_status, current_angle if active_arm != 'Lost' else 0, posture_valid)
            last_viz_frame = viz_frame
            
            # C·∫≠p nh·∫≠t th√¥ng s·ªë
            metric_count.metric("S·ªë l·∫ßn (Reps)", f"{counter}")
            metric_stage.metric("Tr·∫°ng th√°i", f"{stage}")
            if posture_valid: metric_pose.success(f"{posture_status}")
            else: metric_pose.error(f"{posture_status}")

        else:
            if last_viz_frame is not None: viz_frame = last_viz_frame
            else: viz_frame = frame

        # --- B∆Ø·ªöC 3: HI·ªÇN TH·ªä STREAMLIT ---
        # use_container_width=True: Ch√¨a kh√≥a ƒë·ªÉ video t·ª± co gi√£n v·ª´a kh√≠t c·ªôt
        st_frame.image(viz_frame, channels="BGR", use_container_width=True)
        
    cap.release()