# import streamlit as st
# import cv2
# import numpy as np
# import tempfile
# import math
# from mmpose.apis import MMPoseInferencer

# # --- C·∫§U H√åNH ---
# MODEL_CFG = 'rtmpose-m_8xb256-420e_coco-256x192' 
# CONFIDENCE_THRESHOLD = 0.5 
# DOWN_ANGLE_THRESH = 90
# UP_ANGLE_THRESH = 160
# FRAME_SKIP = 5 

# # --- H√ÄM T√çNH G√ìC KHU·ª∂U TAY ---
# def calculate_angle(a, b, c):
#     a, b, c = np.array(a), np.array(b), np.array(c)
#     radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])
#     angle = np.abs(radians * 180.0 / np.pi)
#     if angle > 180.0: angle = 360 - angle
#     return angle

# def check_body_posture(kpts, scores):
#     """
#     Ki·ªÉm tra t∆∞ th·∫ø Push-up h·ªó tr·ª£ c·∫£ g√≥c nghi√™ng (Side) v√† tr·ª±c di·ªán (Front).
#     Input: kpts (m·∫£ng 17x2), scores (m·∫£ng 17)
#     """
#     # Index COCO: L_Shoulder(5), R_Shoulder(6), L_Hip(11), R_Hip(12), L_Ankle(15), R_Ankle(16)
    
#     # 1. L·∫•y t·ªça ƒë·ªô trung b√¨nh Vai v√† H√¥ng
#     shoulder_y = (kpts[5][1] + kpts[6][1]) / 2
#     shoulder_x_dist = abs(kpts[5][0] - kpts[6][0]) # Chi·ªÅu r·ªông vai
    
#     hip_y = (kpts[11][1] + kpts[12][1]) / 2
    
#     # L·∫•y ƒëi·ªÉm ch√¢n (∆∞u ti√™n Ankle, n·∫øu kh√¥ng th·∫•y th√¨ l·∫•y Hip l√†m chu·∫©n t·∫°m)
#     if scores[15] > 0.3 or scores[16] > 0.3:
#         ankle_y = (kpts[15][1] + kpts[16][1]) / 2
#         ankle_x = (kpts[15][0] + kpts[16][0]) / 2
#     else:
#         # N·∫øu ch√¢n b·ªã khu·∫•t (th∆∞·ªùng g·∫∑p ·ªü front view), d√πng H√¥ng ƒë·ªÉ t√≠nh g√≥c
#         ankle_y, ankle_x = hip_y, (kpts[11][0] + kpts[12][0]) / 2

#     shoulder_center_x = (kpts[5][0] + kpts[6][0]) / 2
    
#     # 2. T√≠nh g√≥c nghi√™ng c∆° th·ªÉ (Side View Logic)
#     dy = ankle_y - shoulder_y
#     dx = ankle_x - shoulder_center_x
#     angle_rad = math.atan2(abs(dy), abs(dx))
#     angle_deg = math.degrees(angle_rad)
    
#     # CASE A: N·∫±m ngang (Side View) -> G√≥c < 60 ƒë·ªô
#     if angle_deg < 60:
#         return True, angle_deg, "Side View"

#     # CASE B: H∆∞·ªõng ƒë·∫ßu v√†o Cam (Front View) -> G√≥c ~ 90 ƒë·ªô (ƒê·ª©ng)
#     # L√∫c n√†y ta check t·ª∑ l·ªá Th√¢n / Vai
#     # ·ªû g√≥c tr·ª±c di·ªán, th√¢n (Vai xu·ªëng H√¥ng) b·ªã ng·∫Øn l·∫°i do ph·ªëi c·∫£nh
#     torso_length = abs(hip_y - shoulder_y)
    
#     # Ng∆∞·ª°ng: N·∫øu chi·ªÅu d√†i th√¢n < 1.4 l·∫ßn chi·ªÅu r·ªông vai -> ƒêang n·∫±m h∆∞·ªõng v√†o cam
#     # (Ng∆∞·ªùi ƒë·ª©ng b√¨nh th∆∞·ªùng th√¨ th√¢n d√†i h∆°n vai nhi·ªÅu)
#     if shoulder_x_dist > 0: # Tr√°nh chia cho 0
#         ratio = torso_length / shoulder_x_dist
#         if ratio < 1.4: 
#             return True, angle_deg, f"Front View (R={ratio:.1f})"
    
#     return False, angle_deg, "Stand Up"

# # --- GIAO DI·ªÜN ---
# st.set_page_config(page_title="Smart AI Push-up Counter", layout="wide")
# st.title("üõ°Ô∏è Smart AI Push-up (Anti-Cheat)")
# st.markdown("Phi√™n b·∫£n t√≠ch h·ª£p **Posture Check**: Ch·ªâ ƒë·∫øm khi ng∆∞·ªùi d√πng n·∫±m ·ªü t∆∞ th·∫ø Push-up.")

# st.sidebar.header("C√†i ƒë·∫∑t")
# source_option = st.sidebar.selectbox("Ch·ªçn ngu·ªìn video", ["Webcam", "Upload Video"])

# @st.cache_resource
# def load_model():
#     return MMPoseInferencer(pose2d=MODEL_CFG)

# with st.spinner('ƒêang t·∫£i m√¥ h√¨nh AI...'):
#     inferencer = load_model()

# # --- H√ÄM T√åM KI·∫æM WEBCAM ---
# def get_webcams():
#     """Ki·ªÉm tra 5 c·ªïng ƒë·∫ßu ti√™n (0-4) ƒë·ªÉ t√¨m camera."""
#     available_cams = []
#     # Ki·ªÉm tra 5 index ƒë·∫ßu ti√™n (th∆∞·ªùng camera ch·ªâ n·∫±m trong kho·∫£ng 0-3)
#     for i in range(5): 
#         # Th·ª≠ m·ªü camera v·ªõi backend DirectShow (t·ªët cho Windows/Camera ·∫£o)
#         cap = cv2.VideoCapture(i, cv2.CAP_DSHOW) 
        
#         # N·∫øu kh√¥ng d√πng Windows, ho·∫∑c code tr√™n l·ªói, h√£y th·ª≠ d√≤ng d∆∞·ªõi (b·ªè comment):
#         # cap = cv2.VideoCapture(i) 
        
#         if cap.isOpened():
#             ret, _ = cap.read()
#             if ret:
#                 available_cams.append(i)
#             cap.release()
#     return available_cams

# input_path = None
# if source_option == "Upload Video":
#     uploaded_file = st.sidebar.file_uploader("T·∫£i l√™n video...", type=['mp4', 'mov', 'avi'])
#     if uploaded_file is not None:
#         tfile = tempfile.NamedTemporaryFile(delete=False)
#         tfile.write(uploaded_file.read())
#         input_path = tfile.name
# elif source_option == "Webcam":
#     webcam_indices = get_webcams()
#     if webcam_indices:
#         # T·∫°o danh s√°ch hi·ªÉn th·ªã
#         webcam_options = {f"Webcam {i}": i for i in webcam_indices}
        
#         selected_key = st.sidebar.selectbox(
#             "Ch·ªçn Webcam:", 
#             list(webcam_options.keys())
#         )
#         input_path = webcam_options[selected_key]
#         st.sidebar.info(f"ƒêang s·ª≠ d·ª•ng Webcam {input_path}")
#     else:
#         st.sidebar.error("Kh√¥ng t√¨m th·∫•y webcam n√†o. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi.")

# start_button = st.sidebar.button("B·∫Øt ƒë·∫ßu Ph√¢n t√≠ch", type="primary")
# stop_button = st.sidebar.button("D·ª´ng l·∫°i")

# if start_button and input_path is not None:
#     cap = cv2.VideoCapture(input_path, cv2.CAP_DSHOW)
    
#     width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#     height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
#     # Adaptive Layout
#     if width < height: 
#         col1, col2, col3 = st.columns([2, 2, 2])
#         with col2: st_frame = st.empty()
#     else:
#         col1, col2, col3 = st.columns([0.5, 4, 0.5])
#         with col2: st_frame = st.empty()

#     st_info = st.sidebar.empty()
    
#     counter = 0
#     stage = "UP"
#     active_arm = "None"
#     frame_count = 0
#     posture_status = "Waiting..." # Tr·∫°ng th√°i t∆∞ th·∫ø
#     posture_valid = False
    
#     last_viz_frame = None 

#     while cap.isOpened():
#         if stop_button: break
        
#         ret, frame = cap.read()
#         if not ret:
#             st.sidebar.warning("K·∫øt th√∫c video.")
#             break
            
#         if frame.shape[1] > 1280:
#             scale = 1280 / frame.shape[1]
#             frame = cv2.resize(frame, None, fx=scale, fy=scale)

#         frame_count += 1
        
#         if frame_count % FRAME_SKIP == 0:
#             result_generator = inferencer(frame, return_vis=False)
#             result = next(result_generator)
#             viz_frame = frame.copy()
            
#             predictions = result['predictions'][0]
#             if predictions:
#                 person = predictions[0]
#                 kpts = np.array(person['keypoints'])
#                 scores = np.array(person['keypoint_scores'])

#                 l_pts = [kpts[5], kpts[7], kpts[9]] # Vai, Khu·ª∑u, C·ªï tay tr√°i
#                 r_pts = [kpts[6], kpts[8], kpts[10]] # Vai, Khu·ª∑u, C·ªï tay ph·∫£i
                
#                 # ƒêi·ªÉm d√πng ƒë·ªÉ check t∆∞ th·∫ø: Vai v√† C·ªï ch√¢n (Ankle)
#                 # COCO Ankle: Left(15), Right(16)
#                 # N·∫øu kh√¥ng th·∫•y ch√¢n, d√πng H√¥ng: Left(11), Right(12)
#                 l_body_pts = [kpts[5], kpts[15] if scores[15] > 0.3 else kpts[11]] 
#                 r_body_pts = [kpts[6], kpts[16] if scores[16] > 0.3 else kpts[12]]

#                 l_conf = (scores[5] + scores[7] + scores[9]) / 3
#                 r_conf = (scores[6] + scores[8] + scores[10]) / 3

#                 current_angle = 0
#                 selected_color = (0, 0, 0)
                
#                 # --- CH·ªåN TAY ---
#                 if l_conf > CONFIDENCE_THRESHOLD and l_conf >= r_conf:
#                     active_arm = "Left"
#                     current_angle = calculate_angle(l_pts[0], l_pts[1], l_pts[2])
#                     target_pts, target_elbow = l_pts, l_pts[1]
#                     body_segment = l_body_pts
#                     selected_color = (0, 255, 0)
#                 elif r_conf > CONFIDENCE_THRESHOLD and r_conf > l_conf:
#                     active_arm = "Right"
#                     current_angle = calculate_angle(r_pts[0], r_pts[1], r_pts[2])
#                     target_pts, target_elbow = r_pts, r_pts[1]
#                     body_segment = r_body_pts
#                     selected_color = (255, 165, 0)
#                 else:
#                     active_arm = "Lost"
                
#                 if active_arm != "Lost":
#                     # Truy·ªÅn to√†n b·ªô kpts v√† scores v√†o h√†m m·ªõi
#                     is_valid_pose, body_angle, view_mode = check_body_posture(kpts, scores)
                    
#                     if is_valid_pose:
#                         posture_valid = True
#                         posture_status = f"Push-up ({view_mode})" # Hi·ªán r√µ ƒëang view g√≥c n√†o
                        
#                         # Logic ƒë·∫øm (gi·ªØ nguy√™n)
#                         if current_angle > UP_ANGLE_THRESH: stage = "UP"
#                         if current_angle < DOWN_ANGLE_THRESH and stage == "UP":
#                             stage = "DOWN"
#                             counter += 1
                        
#                         # V·∫Ω m√†u Xanh/Cam
#                         cv2.line(viz_frame, (int(target_pts[0][0]), int(target_pts[0][1])), (int(target_pts[1][0]), int(target_pts[1][1])), selected_color, 4)
#                         cv2.line(viz_frame, (int(target_pts[1][0]), int(target_pts[1][1])), (int(target_pts[2][0]), int(target_pts[2][1])), selected_color, 4)
#                         cv2.putText(viz_frame, str(int(current_angle)), (int(target_elbow[0]), int(target_elbow[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

#                     else:
#                         posture_status = "Stand Up"
#                         # V·∫Ω m√†u ƒê·ªè
#                         cv2.line(viz_frame, (int(target_pts[0][0]), int(target_pts[0][1])), (int(target_pts[1][0]), int(target_pts[1][1])), (0, 0, 255), 4)
#                         cv2.line(viz_frame, (int(target_pts[1][0]), int(target_pts[1][1])), (int(target_pts[2][0]), int(target_pts[2][1])), (0, 0, 255), 4)
#             last_viz_frame = viz_frame
            
#             # C·∫≠p nh·∫≠t th√¥ng s·ªë
#             st_info.markdown(f"""
#             ### üìä Th·ªëng k√™
#             - **S·ªë l·∫ßn:** {counter}
#             - **Tay:** {active_arm}
#             - **T∆∞ th·∫ø:** {posture_status}
#             - **G√≥c g·∫≠p khu·ª∑u tay:** {int(current_angle) if active_arm != 'Lost' else 0}¬∞
#             - **G√≥c nghi√™ng th√¢n:** {int(body_angle) if active_arm != 'Lost' else 0}¬∞
#             """)
        
#         else:
#             if last_viz_frame is not None: viz_frame = last_viz_frame
#             else: viz_frame = frame

#         # V·∫Ω Info Box
#         # ƒê·ªïi m√†u box n·∫øu sai t∆∞ th·∫ø
#         box_color = (0, 200, 0) if posture_valid else (50, 50, 200)
        
#         cv2.rectangle(viz_frame, (0,0), (310, 85), box_color, -1)
#         cv2.putText(viz_frame, f'REPS: {counter}', (10,35), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)
#         cv2.putText(viz_frame, f'{posture_status}', (10,70), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1)

#         st_frame.image(viz_frame, channels="BGR", width='stretch')
        
#     cap.release()


import streamlit as st
import cv2
import numpy as np
import tempfile
import math
from mmpose.apis import MMPoseInferencer

# --- C·∫§U H√åNH GIAO DI·ªÜN & CONSTANTS ---
st.set_page_config(
    page_title="AI Push-up Pro",
    page_icon="üí™",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Gi·ªØ nguy√™n c·∫•u h√¨nh Model
MODEL_CFG = 'rtmpose-m_8xb256-420e_coco-256x192' 
CONFIDENCE_THRESHOLD = 0.5 
DOWN_ANGLE_THRESH = 90
UP_ANGLE_THRESH = 160
FRAME_SKIP = 5 

# --- CSS T√ôY CH·ªàNH (CHO GIAO DI·ªÜN ƒê·∫∏P H∆†N) ---
st.markdown("""
<style>
    [data-testid="stSidebar"] {
        background-color: #1e1e24;
        color: white;
    }
    .stMetric {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 10px;
        border: 1px solid #e0e0e0;
    }
    h1 { color: #FF4B4B; }
    div[data-testid="stVerticalBlock"] > div {
        gap: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# --- GI·ªÆ NGUY√äN LOGIC C·ªêT L√ïI (KH√îNG S·ª¨A) ---
def calculate_angle(a, b, c):
    a, b, c = np.array(a), np.array(b), np.array(c)
    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])
    angle = np.abs(radians * 180.0 / np.pi)
    if angle > 180.0: angle = 360 - angle
    return angle

def check_body_posture(kpts, scores):
    """
    LOGIC V2: Y√™u c·∫ßu th·∫•y to√†n th√¢n (ho·∫∑c √≠t nh·∫•t l√† ƒë·∫ßu g·ªëi) m·ªõi b·∫Øt ƒë·∫ßu x√©t duy·ªát.
    """
    # 1. ƒê·ªãnh nghƒ©a c√°c ƒëi·ªÉm quan tr·ªçng
    # COCO Keypoints: 
    # Vai: 5,6 | H√¥ng: 11,12 | ƒê·∫ßu g·ªëi: 13,14 | C·ªï ch√¢n: 15,16
    
    avg_shoulder_conf = (scores[5] + scores[6]) / 2
    avg_hip_conf = (scores[11] + scores[12]) / 2
    
    # Ki·ªÉm tra xem c√≥ th·∫•y Ch√¢n (Knee ho·∫∑c Ankle) kh√¥ng?
    # Ch·ªâ c·∫ßn th·∫•y 1 trong 2 b√™n (Tr√°i ho·∫∑c Ph·∫£i) l√† ƒë·ªß
    has_knees = scores[13] > 0.4 or scores[14] > 0.4
    has_ankles = scores[15] > 0.4 or scores[16] > 0.4
    
    # --- ƒêI·ªÄU KI·ªÜN 1: PH·∫¢I TH·∫§Y NG∆Ø·ªúI ---
    # N·∫øu kh√¥ng th·∫•y vai, h√¥ng HO·∫∂C (kh√¥ng th·∫•y ƒë·∫ßu g·ªëi V√Ä kh√¥ng th·∫•y c·ªï ch√¢n)
    if avg_shoulder_conf < 0.4 or avg_hip_conf < 0.4 or (not has_knees and not has_ankles):
        return False, 0, "Show Full Body" # B·∫Øt bu·ªôc ph·∫£i l√πi ra xa ƒë·ªÉ th·∫•y ch√¢n

    # 2. L·∫•y t·ªça ƒë·ªô
    shoulder_y = (kpts[5][1] + kpts[6][1]) / 2
    shoulder_center_x = (kpts[5][0] + kpts[6][0]) / 2
    shoulder_width = abs(kpts[5][0] - kpts[6][0])
    
    hip_y = (kpts[11][1] + kpts[12][1]) / 2
    
    # ∆Øu ti√™n l·∫•y Ankle l√†m m·ªëc, n·∫øu kh√¥ng th√¨ l·∫•y Knee (cho ki·ªÉu h√≠t ƒë·∫•t qu·ª≥ g·ªëi)
    if has_ankles:
        foot_y = (kpts[15][1] + kpts[16][1]) / 2
        foot_x = (kpts[15][0] + kpts[16][0]) / 2
        body_part = "Ankles"
    else:
        foot_y = (kpts[13][1] + kpts[14][1]) / 2
        foot_x = (kpts[13][0] + kpts[14][0]) / 2
        body_part = "Knees"

    # 3. T√≠nh g√≥c nghi√™ng th√¢n ng∆∞·ªùi (Vai n·ªëi t·ªõi Ch√¢n)
    dy = foot_y - shoulder_y
    dx = foot_x - shoulder_center_x
    angle_rad = math.atan2(abs(dy), abs(dx))
    angle_deg = math.degrees(angle_rad)
    
    # --- ƒêI·ªÄU KI·ªÜN 2: PH√ÇN LO·∫†I VIEW ---
    
    # CASE A: Side View (N·∫±m ngang) -> G√≥c < 50 ƒë·ªô (Si·∫øt ch·∫∑t h∆°n 60)
    if angle_deg < 50:
        return True, angle_deg, f"Side View ({body_part})"

    # CASE B: Front View (Tr·ª±c di·ªán)
    # Logic: Khi n·∫±m tr·ª±c di·ªán, th√¢n ng∆∞·ªùi (Vai->H√¥ng) s·∫Ω b·ªã ng·∫Øn l·∫°i so v·ªõi Vai.
    torso_length = abs(hip_y - shoulder_y)
    
    if shoulder_width > 0:
        ratio = torso_length / shoulder_width
        # N·∫øu ng·ªìi: Th√¢n r·∫•t d√†i so v·ªõi vai (Ratio > 1.5 - 2.0)
        # N·∫øu h√≠t ƒë·∫•t tr·ª±c di·ªán: Th√¢n ng·∫Øn l·∫°i (Ratio < 1.3)
        if ratio < 1.3: 
            return True, angle_deg, f"Front View (R={ratio:.1f})"
        else:
            return False, angle_deg, "Sitting/Standing" # Ph√°t hi·ªán ng·ªìi
            
    return False, angle_deg, "Wrong Pose"

# --- H√ÄM H·ªñ TR·ª¢ GIAO DI·ªÜN M·ªöI ---
def get_webcams():
    """H√†m t√¨m Webcam c·∫£i ti·∫øn (ƒë√£ fix l·ªói kh√¥ng nh·∫≠n Camo/Virtual Cam)"""
    available_cams = []
    for i in range(4): 
        cap = cv2.VideoCapture(i, cv2.CAP_DSHOW) # Th·ª≠ DSHOW tr∆∞·ªõc cho Windows
        if not cap.isOpened():
            cap = cv2.VideoCapture(i) # Fallback v·ªÅ default
        
        if cap.isOpened():
            available_cams.append(i)
            cap.release()
    return available_cams

def draw_hud(img, counter, stage, posture_status, angle, is_valid):
    """V·∫Ω giao di·ªán HUD ƒë·∫πp h∆°n l√™n frame video"""
    h, w, _ = img.shape
    
    # T·∫°o overlay b√°n trong su·ªët
    overlay = img.copy()
    
    # M√†u s·∫Øc d·ª±a tr√™n tr·∫°ng th√°i
    status_color = (0, 255, 0) if is_valid else (0, 0, 255) # Xanh l√° ho·∫∑c ƒê·ªè
    
    # Thanh Header th√¥ng tin
    cv2.rectangle(overlay, (0, 0), (w, 80), (0, 0, 0), -1)
    
    # Tr·ªôn overlay ƒë·ªÉ t·∫°o ƒë·ªô trong su·ªët
    alpha = 0.7
    cv2.addWeighted(overlay, alpha, img, 1 - alpha, 0, img)
    
    # V·∫Ω th√¥ng tin REPS (To v√† R√µ)
    cv2.putText(img, "REPS", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
    cv2.putText(img, str(counter), (20, 70), cv2.FONT_HERSHEY_DUPLEX, 1.2, (255, 255, 255), 2)
    
    # V·∫Ω Stage (UP/DOWN)
    stage_color = (0, 255, 255) if stage == "DOWN" else (255, 255, 255)
    cv2.putText(img, "STAGE", (150, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
    cv2.putText(img, stage, (150, 70), cv2.FONT_HERSHEY_DUPLEX, 1.0, stage_color, 2)
    
    # V·∫Ω G√≥c (Angle)
    cv2.putText(img, "ANGLE", (300, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
    cv2.putText(img, f"{int(angle)}", (300, 70), cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 2)

    # C·∫£nh b√°o t∆∞ th·∫ø (D∆∞·ªõi ƒë√°y)
    if not is_valid:
        cv2.rectangle(img, (0, h-40), (w, h), (0, 0, 255), -1)
        cv2.putText(img, f"WARNING: {posture_status}", (50, h-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    else:
        # N·∫øu ƒë√∫ng t∆∞ th·∫ø, hi·ªán view mode nh·ªè ·ªü g√≥c
        cv2.putText(img, f"Mode: {posture_status}", (w-250, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

    return img

# --- SIDEBAR & SETUP ---
st.sidebar.title("üõ†Ô∏è Control Panel")
source_option = st.sidebar.radio("Ngu·ªìn Video:", ["Webcam", "Upload Video"])

input_path = None
if source_option == "Upload Video":
    uploaded_file = st.sidebar.file_uploader("Ch·ªçn file video...", type=['mp4', 'mov', 'avi'])
    if uploaded_file is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_file.read())
        input_path = tfile.name
elif source_option == "Webcam":
    # T·ª± ƒë·ªông scan webcam
    webcam_indices = get_webcams()
    if webcam_indices:
        webcam_dict = {f"Camera {i}": i for i in webcam_indices}
        selected_cam = st.sidebar.selectbox("Ch·ªçn thi·∫øt b·ªã:", list(webcam_dict.keys()))
        input_path = webcam_dict[selected_cam]
    else:
        st.sidebar.error("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y Webcam!")

# Load Model
@st.cache_resource
def load_model():
    return MMPoseInferencer(pose2d=MODEL_CFG)

inferencer = None
if st.sidebar.button("üöÄ K√çCH HO·∫†T H·ªÜ TH·ªêNG", type="primary"):
    with st.spinner('ƒêang kh·ªüi ƒë·ªông AI Engine...'):
        inferencer = load_model()
    st.session_state['is_active'] = True
else:
    if 'is_active' not in st.session_state:
        st.session_state['is_active'] = False

stop_button = st.sidebar.button("‚èπÔ∏è D·ª´ng l·∫°i")
if stop_button:
    st.session_state['is_active'] = False

# --- MAIN APP LAYOUT ---
st.title("üí™ AI Push-up Trainer")
st.markdown("H·ªá th·ªëng ƒë·∫øm Push-up th√¥ng minh v·ªõi c√¥ng ngh·ªá **Anti-Cheat Pose Estimation**.")

# T·∫°o placeholder cho layout 2 c·ªôt
main_col1, main_col2 = st.columns([3, 1.2]) # Chia t·ª∑ l·ªá 3:1

with main_col1:
    st_frame = st.empty() # Khung ch·ª©a Video

with main_col2:
    st.subheader("üìä Th·ªëng k√™ Live")
    metric_count = st.empty()
    metric_stage = st.empty()
    metric_angle = st.empty()
    metric_pose = st.empty()
    
    # Kh·ªüi t·∫°o gi√° tr·ªã m·∫∑c ƒë·ªãnh ƒë·∫πp m·∫Øt
    metric_count.metric("S·ªë l·∫ßn (Reps)", "0", "0 reps")
    metric_stage.metric("Tr·∫°ng th√°i", "READY", "---")
    metric_angle.metric("G√≥c tay", "0¬∞", "---")
    st.info("üí° H∆∞·ªõng d·∫´n: N·∫±m xu·ªëng ƒë·ªÉ b·∫Øt ƒë·∫ßu!")


# --- V√íNG L·∫∂P X·ª¨ L√ù (MAIN LOOP) ---
if st.session_state['is_active'] and input_path is not None:
    cap = cv2.VideoCapture(input_path, cv2.CAP_DSHOW) if source_option == "Webcam" else cv2.VideoCapture(input_path)
    
    counter = 0
    stage = "UP"
    active_arm = "None"
    frame_count = 0
    posture_status = "Waiting..."
    posture_valid = False
    
    last_viz_frame = None 

    while cap.isOpened() and st.session_state['is_active']:
        ret, frame = cap.read()
        if not ret:
            st.warning("ƒê√£ h·∫øt video ho·∫∑c m·∫•t k·∫øt n·ªëi camera.")
            st.session_state['is_active'] = False
            break
            
        # Resize nh·∫π ƒë·ªÉ tƒÉng t·ªëc hi·ªÉn th·ªã n·∫øu video qu√° to
        if frame.shape[1] > 1000:
            scale = 1000 / frame.shape[1]
            frame = cv2.resize(frame, None, fx=scale, fy=scale)

        frame_count += 1
        
        # --- LOGIC AI (GI·ªÆ NGUY√äN) ---
        if frame_count % FRAME_SKIP == 0:
            result_generator = inferencer(frame, return_vis=False)
            result = next(result_generator)
            viz_frame = frame.copy()
            
            predictions = result['predictions'][0]
            if predictions:
                person = predictions[0]
                kpts = np.array(person['keypoints'])
                scores = np.array(person['keypoint_scores'])

                l_pts = [kpts[5], kpts[7], kpts[9]]
                r_pts = [kpts[6], kpts[8], kpts[10]]
                l_body_pts = [kpts[5], kpts[15] if scores[15] > 0.3 else kpts[11]] 
                r_body_pts = [kpts[6], kpts[16] if scores[16] > 0.3 else kpts[12]]
                l_conf = (scores[5] + scores[7] + scores[9]) / 3
                r_conf = (scores[6] + scores[8] + scores[10]) / 3

                current_angle = 0
                
                # Logic ch·ªçn tay
                if l_conf > CONFIDENCE_THRESHOLD and l_conf >= r_conf:
                    active_arm = "Left"
                    current_angle = calculate_angle(l_pts[0], l_pts[1], l_pts[2])
                    target_pts = l_pts
                elif r_conf > CONFIDENCE_THRESHOLD and r_conf > l_conf:
                    active_arm = "Right"
                    current_angle = calculate_angle(r_pts[0], r_pts[1], r_pts[2])
                    target_pts = r_pts
                else:
                    active_arm = "Lost"
                
                if active_arm != "Lost":
                    is_valid_pose, body_angle, view_mode = check_body_posture(kpts, scores)
                    posture_valid = is_valid_pose
                    
                    # Logic hi·ªÉn th·ªã tr·∫°ng th√°i
                    posture_status = view_mode # L·∫•y text tr·ª±c ti·∫øp t·ª´ h√†m (Show Full Body, Sitting...)

                    if is_valid_pose:
                        # ... (Gi·ªØ nguy√™n logic ƒë·∫øm UP/DOWN c≈©) ...
                        if current_angle > UP_ANGLE_THRESH: stage = "UP"
                        if current_angle < DOWN_ANGLE_THRESH and stage == "UP":
                            stage = "DOWN"
                            counter += 1
                        
                        # V·∫Ω XANH (H·ª£p l·ªá)
                        cv2.line(viz_frame, (int(target_pts[0][0]), int(target_pts[0][1])), (int(target_pts[1][0]), int(target_pts[1][1])), (0, 255, 0), 4)
                        cv2.line(viz_frame, (int(target_pts[1][0]), int(target_pts[1][1])), (int(target_pts[2][0]), int(target_pts[2][1])), (0, 255, 0), 4)
                    else:
                        # V·∫Ω ƒê·ªé (Kh√¥ng h·ª£p l·ªá)
                        cv2.line(viz_frame, (int(target_pts[0][0]), int(target_pts[0][1])), (int(target_pts[1][0]), int(target_pts[1][1])), (0, 0, 255), 4)
                        cv2.line(viz_frame, (int(target_pts[1][0]), int(target_pts[1][1])), (int(target_pts[2][0]), int(target_pts[2][1])), (0, 0, 255), 4)
            
            # --- C·∫¨P NH·∫¨T GIAO DI·ªÜN M·ªöI ---
            # G·ªçi h√†m v·∫Ω HUD m·ªõi
            viz_frame = draw_hud(viz_frame, counter, stage, posture_status, current_angle if active_arm != 'Lost' else 0, posture_valid)
            last_viz_frame = viz_frame
            
            # C·∫≠p nh·∫≠t Widget b√™n ph·∫£i
            metric_count.metric("S·ªë l·∫ßn (Reps)", f"{counter}", delta="TƒÉng d·∫ßn")
            metric_stage.metric("Tr·∫°ng th√°i", f"{stage}", delta_color="off" if stage=="UP" else "inverse")
            metric_angle.metric("G√≥c tay", f"{int(current_angle)}¬∞" if active_arm != 'Lost' else "0¬∞")
            
            if posture_valid:
                metric_pose.success(f"T∆∞ th·∫ø: {posture_status}")
            else:
                metric_pose.error(f"T∆∞ th·∫ø: {posture_status}")

        else:
            if last_viz_frame is not None: viz_frame = last_viz_frame
            else: viz_frame = frame

        # Hi·ªÉn th·ªã h√¨nh ·∫£nh
        st_frame.image(viz_frame, channels="BGR", use_container_width=True)
        
    cap.release()