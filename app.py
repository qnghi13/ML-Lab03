import streamlit as st
import cv2
import numpy as np
import tempfile
import math
from mmpose.apis import MMPoseInferencer

# --- C·∫§U H√åNH ---
MODEL_CFG = 'rtmpose-m_8xb256-420e_coco-256x192' 
CONFIDENCE_THRESHOLD = 0.5 
DOWN_ANGLE_THRESH = 90
UP_ANGLE_THRESH = 160
FRAME_SKIP = 5 

# --- H√ÄM T√çNH G√ìC KHU·ª∂U TAY ---
def calculate_angle(a, b, c):
    a, b, c = np.array(a), np.array(b), np.array(c)
    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])
    angle = np.abs(radians * 180.0 / np.pi)
    if angle > 180.0: angle = 360 - angle
    return angle

def check_body_posture(kpts, scores):
    """
    Ki·ªÉm tra t∆∞ th·∫ø Push-up h·ªó tr·ª£ c·∫£ g√≥c nghi√™ng (Side) v√† tr·ª±c di·ªán (Front).
    Input: kpts (m·∫£ng 17x2), scores (m·∫£ng 17)
    """
    # Index COCO: L_Shoulder(5), R_Shoulder(6), L_Hip(11), R_Hip(12), L_Ankle(15), R_Ankle(16)
    
    # 1. L·∫•y t·ªça ƒë·ªô trung b√¨nh Vai v√† H√¥ng
    shoulder_y = (kpts[5][1] + kpts[6][1]) / 2
    shoulder_x_dist = abs(kpts[5][0] - kpts[6][0]) # Chi·ªÅu r·ªông vai
    
    hip_y = (kpts[11][1] + kpts[12][1]) / 2
    
    # L·∫•y ƒëi·ªÉm ch√¢n (∆∞u ti√™n Ankle, n·∫øu kh√¥ng th·∫•y th√¨ l·∫•y Hip l√†m chu·∫©n t·∫°m)
    if scores[15] > 0.3 or scores[16] > 0.3:
        ankle_y = (kpts[15][1] + kpts[16][1]) / 2
        ankle_x = (kpts[15][0] + kpts[16][0]) / 2
    else:
        # N·∫øu ch√¢n b·ªã khu·∫•t (th∆∞·ªùng g·∫∑p ·ªü front view), d√πng H√¥ng ƒë·ªÉ t√≠nh g√≥c
        ankle_y, ankle_x = hip_y, (kpts[11][0] + kpts[12][0]) / 2

    shoulder_center_x = (kpts[5][0] + kpts[6][0]) / 2
    
    # 2. T√≠nh g√≥c nghi√™ng c∆° th·ªÉ (Side View Logic)
    dy = ankle_y - shoulder_y
    dx = ankle_x - shoulder_center_x
    angle_rad = math.atan2(abs(dy), abs(dx))
    angle_deg = math.degrees(angle_rad)
    
    # CASE A: N·∫±m ngang (Side View) -> G√≥c < 60 ƒë·ªô
    if angle_deg < 60:
        return True, angle_deg, "Side View"

    # CASE B: H∆∞·ªõng ƒë·∫ßu v√†o Cam (Front View) -> G√≥c ~ 90 ƒë·ªô (ƒê·ª©ng)
    # L√∫c n√†y ta check t·ª∑ l·ªá Th√¢n / Vai
    # ·ªû g√≥c tr·ª±c di·ªán, th√¢n (Vai xu·ªëng H√¥ng) b·ªã ng·∫Øn l·∫°i do ph·ªëi c·∫£nh
    torso_length = abs(hip_y - shoulder_y)
    
    # Ng∆∞·ª°ng: N·∫øu chi·ªÅu d√†i th√¢n < 1.4 l·∫ßn chi·ªÅu r·ªông vai -> ƒêang n·∫±m h∆∞·ªõng v√†o cam
    # (Ng∆∞·ªùi ƒë·ª©ng b√¨nh th∆∞·ªùng th√¨ th√¢n d√†i h∆°n vai nhi·ªÅu)
    if shoulder_x_dist > 0: # Tr√°nh chia cho 0
        ratio = torso_length / shoulder_x_dist
        if ratio < 1.4: 
            return True, angle_deg, f"Front View (R={ratio:.1f})"
    
    return False, angle_deg, "Stand Up"

# --- GIAO DI·ªÜN ---
st.set_page_config(page_title="Smart AI Push-up Counter", layout="wide")
st.title("üõ°Ô∏è Smart AI Push-up (Anti-Cheat)")
st.markdown("Phi√™n b·∫£n t√≠ch h·ª£p **Posture Check**: Ch·ªâ ƒë·∫øm khi ng∆∞·ªùi d√πng n·∫±m ·ªü t∆∞ th·∫ø Push-up.")

st.sidebar.header("C√†i ƒë·∫∑t")
source_option = st.sidebar.selectbox("Ch·ªçn ngu·ªìn video", ["Webcam", "Upload Video"])

@st.cache_resource
def load_model():
    return MMPoseInferencer(pose2d=MODEL_CFG)

with st.spinner('ƒêang t·∫£i m√¥ h√¨nh AI...'):
    inferencer = load_model()

# --- H√ÄM T√åM KI·∫æM WEBCAM ---
def get_webcams():
    """Ki·ªÉm tra 5 c·ªïng ƒë·∫ßu ti√™n (0-4) ƒë·ªÉ t√¨m camera."""
    available_cams = []
    # Ki·ªÉm tra 5 index ƒë·∫ßu ti√™n (th∆∞·ªùng camera ch·ªâ n·∫±m trong kho·∫£ng 0-3)
    for i in range(5): 
        # Th·ª≠ m·ªü camera v·ªõi backend DirectShow (t·ªët cho Windows/Camera ·∫£o)
        cap = cv2.VideoCapture(i, cv2.CAP_DSHOW) 
        
        # N·∫øu kh√¥ng d√πng Windows, ho·∫∑c code tr√™n l·ªói, h√£y th·ª≠ d√≤ng d∆∞·ªõi (b·ªè comment):
        # cap = cv2.VideoCapture(i) 
        
        if cap.isOpened():
            ret, _ = cap.read()
            if ret:
                available_cams.append(i)
            cap.release()
    return available_cams

input_path = None
if source_option == "Upload Video":
    uploaded_file = st.sidebar.file_uploader("T·∫£i l√™n video...", type=['mp4', 'mov', 'avi'])
    if uploaded_file is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_file.read())
        input_path = tfile.name
elif source_option == "Webcam":
    webcam_indices = get_webcams()
    if webcam_indices:
        # T·∫°o danh s√°ch hi·ªÉn th·ªã
        webcam_options = {f"Webcam {i}": i for i in webcam_indices}
        
        selected_key = st.sidebar.selectbox(
            "Ch·ªçn Webcam:", 
            list(webcam_options.keys())
        )
        input_path = webcam_options[selected_key]
        st.sidebar.info(f"ƒêang s·ª≠ d·ª•ng Webcam {input_path}")
    else:
        st.sidebar.error("Kh√¥ng t√¨m th·∫•y webcam n√†o. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi.")

start_button = st.sidebar.button("B·∫Øt ƒë·∫ßu Ph√¢n t√≠ch", type="primary")
stop_button = st.sidebar.button("D·ª´ng l·∫°i")

if start_button and input_path is not None:
    cap = cv2.VideoCapture(input_path, cv2.CAP_DSHOW)
    
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    # Adaptive Layout
    if width < height: 
        col1, col2, col3 = st.columns([2, 2, 2])
        with col2: st_frame = st.empty()
    else:
        col1, col2, col3 = st.columns([0.5, 4, 0.5])
        with col2: st_frame = st.empty()

    st_info = st.sidebar.empty()
    
    counter = 0
    stage = "UP"
    active_arm = "None"
    frame_count = 0
    posture_status = "Waiting..." # Tr·∫°ng th√°i t∆∞ th·∫ø
    posture_valid = False
    
    last_viz_frame = None 

    while cap.isOpened():
        if stop_button: break
        
        ret, frame = cap.read()
        if not ret:
            st.sidebar.warning("K·∫øt th√∫c video.")
            break
            
        if frame.shape[1] > 1280:
            scale = 1280 / frame.shape[1]
            frame = cv2.resize(frame, None, fx=scale, fy=scale)

        frame_count += 1
        
        if frame_count % FRAME_SKIP == 0:
            result_generator = inferencer(frame, return_vis=False)
            result = next(result_generator)
            viz_frame = frame.copy()
            
            predictions = result['predictions'][0]
            if predictions:
                person = predictions[0]
                kpts = np.array(person['keypoints'])
                scores = np.array(person['keypoint_scores'])

                l_pts = [kpts[5], kpts[7], kpts[9]] # Vai, Khu·ª∑u, C·ªï tay tr√°i
                r_pts = [kpts[6], kpts[8], kpts[10]] # Vai, Khu·ª∑u, C·ªï tay ph·∫£i
                
                # ƒêi·ªÉm d√πng ƒë·ªÉ check t∆∞ th·∫ø: Vai v√† C·ªï ch√¢n (Ankle)
                # COCO Ankle: Left(15), Right(16)
                # N·∫øu kh√¥ng th·∫•y ch√¢n, d√πng H√¥ng: Left(11), Right(12)
                l_body_pts = [kpts[5], kpts[15] if scores[15] > 0.3 else kpts[11]] 
                r_body_pts = [kpts[6], kpts[16] if scores[16] > 0.3 else kpts[12]]

                l_conf = (scores[5] + scores[7] + scores[9]) / 3
                r_conf = (scores[6] + scores[8] + scores[10]) / 3

                current_angle = 0
                selected_color = (0, 0, 0)
                
                # --- CH·ªåN TAY ---
                if l_conf > CONFIDENCE_THRESHOLD and l_conf >= r_conf:
                    active_arm = "Left"
                    current_angle = calculate_angle(l_pts[0], l_pts[1], l_pts[2])
                    target_pts, target_elbow = l_pts, l_pts[1]
                    body_segment = l_body_pts
                    selected_color = (0, 255, 0)
                elif r_conf > CONFIDENCE_THRESHOLD and r_conf > l_conf:
                    active_arm = "Right"
                    current_angle = calculate_angle(r_pts[0], r_pts[1], r_pts[2])
                    target_pts, target_elbow = r_pts, r_pts[1]
                    body_segment = r_body_pts
                    selected_color = (255, 165, 0)
                else:
                    active_arm = "Lost"
                
                if active_arm != "Lost":
                    # Truy·ªÅn to√†n b·ªô kpts v√† scores v√†o h√†m m·ªõi
                    is_valid_pose, body_angle, view_mode = check_body_posture(kpts, scores)
                    
                    if is_valid_pose:
                        posture_valid = True
                        posture_status = f"Push-up ({view_mode})" # Hi·ªán r√µ ƒëang view g√≥c n√†o
                        
                        # Logic ƒë·∫øm (gi·ªØ nguy√™n)
                        if current_angle > UP_ANGLE_THRESH: stage = "UP"
                        if current_angle < DOWN_ANGLE_THRESH and stage == "UP":
                            stage = "DOWN"
                            counter += 1
                        
                        # V·∫Ω m√†u Xanh/Cam
                        cv2.line(viz_frame, (int(target_pts[0][0]), int(target_pts[0][1])), (int(target_pts[1][0]), int(target_pts[1][1])), selected_color, 4)
                        cv2.line(viz_frame, (int(target_pts[1][0]), int(target_pts[1][1])), (int(target_pts[2][0]), int(target_pts[2][1])), selected_color, 4)
                        cv2.putText(viz_frame, str(int(current_angle)), (int(target_elbow[0]), int(target_elbow[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

                    else:
                        posture_status = "Stand Up"
                        # V·∫Ω m√†u ƒê·ªè
                        cv2.line(viz_frame, (int(target_pts[0][0]), int(target_pts[0][1])), (int(target_pts[1][0]), int(target_pts[1][1])), (0, 0, 255), 4)
                        cv2.line(viz_frame, (int(target_pts[1][0]), int(target_pts[1][1])), (int(target_pts[2][0]), int(target_pts[2][1])), (0, 0, 255), 4)
            last_viz_frame = viz_frame
            
            # C·∫≠p nh·∫≠t th√¥ng s·ªë
            st_info.markdown(f"""
            ### üìä Th·ªëng k√™
            - **S·ªë l·∫ßn:** {counter}
            - **Tay:** {active_arm}
            - **T∆∞ th·∫ø:** {posture_status}
            - **G√≥c g·∫≠p khu·ª∑u tay:** {int(current_angle) if active_arm != 'Lost' else 0}¬∞
            - **G√≥c nghi√™ng th√¢n:** {int(body_angle) if active_arm != 'Lost' else 0}¬∞
            """)
        
        else:
            if last_viz_frame is not None: viz_frame = last_viz_frame
            else: viz_frame = frame

        # V·∫Ω Info Box
        # ƒê·ªïi m√†u box n·∫øu sai t∆∞ th·∫ø
        box_color = (0, 200, 0) if posture_valid else (50, 50, 200)
        
        cv2.rectangle(viz_frame, (0,0), (310, 85), box_color, -1)
        cv2.putText(viz_frame, f'REPS: {counter}', (10,35), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)
        cv2.putText(viz_frame, f'{posture_status}', (10,70), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1)

        st_frame.image(viz_frame, channels="BGR", width='stretch')
        
    cap.release()